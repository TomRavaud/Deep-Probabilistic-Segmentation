{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualize a prediction of the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interactive plots (needs ipympl and ipywidgets)\n",
    "# %matplotlib widget\n",
    "\n",
    "# For static plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# Add the src directory to the system path\n",
    "# (to avoid having to install project as a package)\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "# Third-party libraries\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import omegaconf\n",
    "\n",
    "# Custom modules\n",
    "from toolbox.modules.object_segmentation_prediction_module import (\n",
    "    ObjectSegmentationPredictionModule,\n",
    "    BatchInferenceData,\n",
    ")\n",
    "from toolbox.modules.probabilistic_segmentation_lookup import (\n",
    "    ProbabilisticSegmentationLookup,\n",
    ")\n",
    "from toolbox.modules.probabilistic_segmentation_mlp import (\n",
    "    ProbabilisticSegmentationMLP,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate the model and load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dir = pathlib.Path(\"../logs/train/runs\")\n",
    "checkpoint = None\n",
    "\n",
    "if checkpoint is None:\n",
    "    # Get the last checkpoint\n",
    "    logs_dir = sorted(runs_dir.iterdir())[-1]\n",
    "else:\n",
    "    # Get the checkpoint with the specified name\n",
    "    logs_dir = runs_dir / checkpoint\n",
    "\n",
    "print(f\"Loading checkpoint from {logs_dir}\")\n",
    "\n",
    "# Load the state_dict of the model from the checkpoint\n",
    "train_module_state_dict = torch.load(logs_dir / \"checkpoints/last.ckpt\").get(\"state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace each prefix in the state_dict\n",
    "# new_state_dict = {}\n",
    "# for key, value in train_module_state_dict.items():\n",
    "#     new_state_dict[key.replace(\"_model._probabilistic_segmentation_model._resnet18.\", \"\")] = value\n",
    "\n",
    "# # Save the new state_dict\n",
    "# torch.save(new_state_dict, \"../weights/resnet18.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the probabilistic segmentation model to use\n",
    "# probabilistic_segmentation_model = ProbabilisticSegmentationLookup(\n",
    "#     color_space=\"rgb\",\n",
    "#     nb_bins=(32, 32, 32),\n",
    "#     use_histograms=True,\n",
    "#     output_logits=False,\n",
    "# )\n",
    "\n",
    "probabilistic_segmentation_model = ProbabilisticSegmentationMLP(\n",
    "    patch_size=5,\n",
    "    output_logits=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model used for prediction\n",
    "prediction_module = ObjectSegmentationPredictionModule(\n",
    "    probabilistic_segmentation_model=probabilistic_segmentation_model,\n",
    ")\n",
    "\n",
    "def match_state_dict(state_dict: dict, model: torch.nn.Module) -> dict:\n",
    "    \"\"\"Extract the state_dict of the model from an other state_dict by matching their\n",
    "    keys.\n",
    "\n",
    "    Args:\n",
    "        state_dict (dict): The state_dict from which to extract the model's state_dict.\n",
    "        model (torch.nn.Module): The model for which to extract the state_dict.\n",
    "\n",
    "    Returns:\n",
    "        dict: The state_dict of the model.\n",
    "    \"\"\"\n",
    "    model_state_dict = model.state_dict()\n",
    "    new_state_dict = {\n",
    "        key: value\n",
    "        for key, value in state_dict.items()\n",
    "        if key in model_state_dict\n",
    "    }\n",
    "    \n",
    "    model_state_dict.update(new_state_dict)\n",
    "    \n",
    "    return model_state_dict\n",
    "\n",
    "# Get the state_dict of the model used for prediction from the pretrained model\n",
    "prediction_module_state_dict = match_state_dict(\n",
    "    train_module_state_dict,\n",
    "    prediction_module,\n",
    ")\n",
    "\n",
    "# Load the state_dict into the model\n",
    "prediction_module.load_state_dict(prediction_module_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a sample image and set a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image to segment\n",
    "# image = plt.imread(\"images/gso_bag.png\")\n",
    "# image = plt.imread(\"images/gso_bowl.png\")\n",
    "# image = plt.imread(\"images/gso_coffee.png\")\n",
    "# image = plt.imread(\"images/gso_dog_bowl.png\")\n",
    "# image = plt.imread(\"images/gso_jarro.png\")\n",
    "# image = plt.imread(\"images/gso_nips.png\")\n",
    "# image = plt.imread(\"images/gso_pikachu.png\")\n",
    "# image = plt.imread(\"images/gso_sheep.png\")\n",
    "image = plt.imread(\"images/gso_skip.png\")\n",
    "# image = plt.imread(\"images/gso_spiderman.png\")\n",
    "\n",
    "# Remove the alpha channel if it exists\n",
    "if image.shape[-1] == 4:\n",
    "    image = image[..., :3]\n",
    "\n",
    "# Convert [0, 1] to [0, 255] and to uint8\n",
    "image = (image * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "# Set the bounding box of the object to segment\n",
    "# bbox = [265, 190, 420, 335]  # cat (cat_rbot.png)\n",
    "# bbox = [275, 80, 410, 190]  # horse (cat_rbot.png)\n",
    "# bbox = [0, 260, 170, 400]  # glue gun (cat_rbot.png)\n",
    "\n",
    "# bbox = [223, 68, 311, 185]  # bag (gso_bag.png)\n",
    "# bbox = [49, 123, 112, 198]  # turquoise bowl (gso_bowl.png)\n",
    "# bbox = [9, 154, 109, 210]  # coffee box (gso_coffee.png)\n",
    "# bbox = [159, 0, 278, 110]  # dog bowl (gso_dog_bowl.png)\n",
    "# bbox = [46, 58, 104, 148]  # jarro (gso_jarro.png)\n",
    "# bbox = [4, 49, 133, 202]  # nips (gso_nips.png)\n",
    "# bbox = [151, 0, 314, 70]  # pikachu (gso_pikachu.png)\n",
    "# bbox = [106, 106, 225, 196]  # sheep (gso_sheep.png)\n",
    "bbox = [80, 45, 227, 192]  # skip (gso_skip.png)\n",
    "# bbox = [176, 28, 237, 98]  # spiderman (gso_spiderman.png)\n",
    "\n",
    "\n",
    "# Draw the bounding box on the image\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "rect = patches.Rectangle(\n",
    "    (bbox[0], bbox[1]),\n",
    "    bbox[2] - bbox[0],\n",
    "    bbox[3] - bbox[1],\n",
    "    linewidth=1,\n",
    "    edgecolor=\"r\",\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "ax.axis(\"off\")\n",
    "plt.title(\"Input image with bounding box\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the input data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = BatchInferenceData(\n",
    "    rgbs=torch.tensor(image).permute(2, 0, 1).unsqueeze(0),\n",
    "    contour_points_list=[\n",
    "            # First example of the batch\n",
    "            [np.array(bbox).reshape(-1, 2),],\n",
    "            # Second example of the batch...\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "prediction_module = prediction_module.to(device)\n",
    "input.rgbs = input.rgbs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "prediction_module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the prediction\n",
    "predicted_probabilistic_masks = prediction_module(\n",
    "    input,\n",
    "    pixel_segmentation_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileSAM mask\n",
    "sam_masks = prediction_module.model.binary_masks\n",
    "\n",
    "if sam_masks is None:\n",
    "    print(\"No MobileSAM mask found\")\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    \n",
    "    sam_mask = sam_masks.squeeze().cpu().numpy()\n",
    "    img = ax.imshow(sam_mask, cmap=\"magma\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # Colorbar\n",
    "    fig.colorbar(img, cmap=\"magma\", cax=cax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module mask\n",
    "predicted_probabilistic_mask = predicted_probabilistic_masks.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the mask\n",
    "fig, ax = plt.subplots()\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "# Mask\n",
    "if sam_masks is None:\n",
    "    # Get the image to set the color scale\n",
    "    img = ax.imshow(predicted_probabilistic_mask, cmap=\"magma\")\n",
    "else:\n",
    "    # Use the same color scale as the MobileSAM mask\n",
    "    ax.imshow(predicted_probabilistic_mask, cmap=\"magma\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Colorbar\n",
    "fig.colorbar(img, cmap=\"magma\", cax=cax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
